{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from PIL import Image\n",
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class COCODataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, annotation_file, image_dir, classes, transform=None):\n",
    "        with open(annotation_file, 'r') as f:\n",
    "            self.coco_data = json.load(f)\n",
    "        self.image_dir = image_dir\n",
    "        self.classes = classes\n",
    "        self.transform = transform\n",
    "\n",
    "        self.image_annotations = {img['id']: [] for img in self.coco_data['images']}\n",
    "        for ann in self.coco_data['annotations']:\n",
    "            self.image_annotations[ann['image_id']].append(ann)\n",
    "        \n",
    "        #Identify the background image\n",
    "        filtered_images = [\n",
    "            img for img in self.coco_data['images']\n",
    "            if len(self.image_annotations[img['id']]) == 0\n",
    "        ]\n",
    "\n",
    "        #Select 100% of non annotated to be removed\n",
    "        num_to_remove = int(len(filtered_images) * 1)\n",
    "        images_to_remove = random.sample(filtered_images, num_to_remove)\n",
    "        images_to_remove_ids = {img['id'] for img in images_to_remove}\n",
    "\n",
    "        #Remove the selected images\n",
    "        self.coco_data['images'] = [\n",
    "            img for img in self.coco_data['images']\n",
    "            if img['id'] not in images_to_remove_ids\n",
    "        ]\n",
    "\n",
    "        #Remove the annotations as well\n",
    "        self.coco_data['annotations'] = [\n",
    "            ann for ann in self.coco_data['annotations']\n",
    "            if ann['image_id'] in {img['id'] for img in self.coco_data['images']}\n",
    "        ]\n",
    "\n",
    "        #Rebuild the annotations\n",
    "        self.image_annotations = {img['id']: [] for img in self.coco_data['images']}\n",
    "        for ann in self.coco_data['annotations']:\n",
    "            self.image_annotations[ann['image_id']].append(ann)\n",
    "\n",
    "        self.images = self.coco_data['images']\n",
    "        self.image_ids = [img['id'] for img in self.coco_data['images']]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_data = self.images[idx]\n",
    "        image_id = image_data['id']\n",
    "        image_path = f\"{self.image_dir}/{image_data['file_name']}\"\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        annotations = self.image_annotations[image_id]\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for ann in annotations:\n",
    "            x, y, w, h = ann['bbox']\n",
    "            boxes.append([x, y, x + w, y + h])\n",
    "            labels.append(int(ann['category_id']))\n",
    "        \n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        image_id = torch.tensor([image_id])\n",
    "\n",
    "        target = {\n",
    "            'boxes': boxes,\n",
    "            'labels': labels, \n",
    "            'image_id': image_id\n",
    "        }\n",
    "        return image, target\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu118\n",
      "0.20.1+cu118\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_path = \"instances_Train.json\"\n",
    "frames_path = \"frames\"\n",
    "classes = {0: \"No_hit\", 1: \"Hit\", 3:\"Oc_hit\", 4:\"Full_occ\"}\n",
    "transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = COCODataset(annotations_path, frames_path, classes, transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_indices = np.arange(len(dataset.image_ids))\n",
    "train_indices, test_indices = train_test_split(remaining_indices, test_size=0.2, random_state=10)\n",
    "\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "test_dataset = Subset(dataset, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    max_boxes = max([len(item[1]['boxes']) for item in batch])\n",
    "\n",
    "    images = []\n",
    "    targets = []\n",
    "\n",
    "    for img, target in batch:\n",
    "        boxes = target['boxes']\n",
    "        labels = target['labels']\n",
    "\n",
    "        if len(boxes) < max_boxes:\n",
    "            pad_size = max_boxes - len(boxes)\n",
    "            boxes = torch.cat([boxes, torch.zeros(pad_size, 4)], dim=0)\n",
    "            labels = torch.cat([labels, torch.zeros(pad_size, dtype=torch.int64)], dim=0)\n",
    "        \n",
    "        targets.append({\n",
    "            'boxes': boxes,\n",
    "            'labels': labels,\n",
    "            'image_id': target['image_id']\n",
    "        })\n",
    "\n",
    "        images.append(img)\n",
    "    \n",
    "    return images, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, pin_memory=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, pin_memory=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 loaded successfully.\n",
      "Batch 1 loaded successfully.\n",
      "Batch 2 loaded successfully.\n",
      "Batch 3 loaded successfully.\n",
      "Batch 4 loaded successfully.\n",
      "Batch 5 loaded successfully.\n",
      "Batch 6 loaded successfully.\n",
      "Batch 7 loaded successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 8 loaded successfully.\n",
      "Batch 9 loaded successfully.\n",
      "Batch 10 loaded successfully.\n",
      "Batch 11 loaded successfully.\n",
      "Batch 12 loaded successfully.\n",
      "Batch 13 loaded successfully.\n",
      "Batch 14 loaded successfully.\n",
      "Batch 15 loaded successfully.\n",
      "Batch 16 loaded successfully.\n",
      "Batch 17 loaded successfully.\n",
      "Batch 18 loaded successfully.\n",
      "Batch 19 loaded successfully.\n",
      "Batch 20 loaded successfully.\n",
      "Batch 21 loaded successfully.\n",
      "Batch 22 loaded successfully.\n",
      "Batch 23 loaded successfully.\n",
      "Batch 24 loaded successfully.\n",
      "Batch 25 loaded successfully.\n",
      "Batch 26 loaded successfully.\n",
      "Batch 27 loaded successfully.\n",
      "Batch 28 loaded successfully.\n",
      "Batch 29 loaded successfully.\n",
      "Batch 30 loaded successfully.\n",
      "Batch 31 loaded successfully.\n",
      "Batch 32 loaded successfully.\n",
      "Batch 33 loaded successfully.\n",
      "Batch 34 loaded successfully.\n",
      "Batch 35 loaded successfully.\n",
      "Batch 36 loaded successfully.\n",
      "Batch 37 loaded successfully.\n",
      "Batch 38 loaded successfully.\n",
      "Batch 39 loaded successfully.\n",
      "Batch 40 loaded successfully.\n",
      "Batch 41 loaded successfully.\n",
      "Batch 42 loaded successfully.\n",
      "Batch 43 loaded successfully.\n",
      "Batch 44 loaded successfully.\n",
      "Batch 45 loaded successfully.\n",
      "Batch 46 loaded successfully.\n",
      "Batch 47 loaded successfully.\n",
      "Batch 48 loaded successfully.\n",
      "Batch 49 loaded successfully.\n",
      "Batch 50 loaded successfully.\n",
      "Batch 51 loaded successfully.\n",
      "Batch 52 loaded successfully.\n",
      "Batch 53 loaded successfully.\n",
      "Batch 54 loaded successfully.\n",
      "Batch 55 loaded successfully.\n",
      "Batch 56 loaded successfully.\n",
      "Batch 57 loaded successfully.\n",
      "Batch 58 loaded successfully.\n",
      "Batch 59 loaded successfully.\n",
      "Batch 60 loaded successfully.\n",
      "Batch 61 loaded successfully.\n",
      "Batch 62 loaded successfully.\n",
      "Batch 63 loaded successfully.\n",
      "Batch 64 loaded successfully.\n",
      "Batch 65 loaded successfully.\n",
      "Batch 66 loaded successfully.\n",
      "Batch 67 loaded successfully.\n",
      "Batch 68 loaded successfully.\n",
      "Batch 69 loaded successfully.\n",
      "Batch 70 loaded successfully.\n",
      "Batch 71 loaded successfully.\n",
      "Batch 72 loaded successfully.\n",
      "Batch 73 loaded successfully.\n",
      "Batch 74 loaded successfully.\n",
      "Batch 75 loaded successfully.\n",
      "Batch 76 loaded successfully.\n",
      "Batch 77 loaded successfully.\n",
      "Batch 78 loaded successfully.\n",
      "Batch 79 loaded successfully.\n",
      "Batch 80 loaded successfully.\n",
      "Batch 81 loaded successfully.\n",
      "Batch 82 loaded successfully.\n",
      "Batch 83 loaded successfully.\n",
      "Batch 84 loaded successfully.\n",
      "Batch 85 loaded successfully.\n",
      "Batch 86 loaded successfully.\n",
      "Batch 87 loaded successfully.\n",
      "Batch 88 loaded successfully.\n",
      "Batch 89 loaded successfully.\n",
      "Batch 90 loaded successfully.\n",
      "Batch 91 loaded successfully.\n",
      "Batch 92 loaded successfully.\n",
      "Batch 93 loaded successfully.\n",
      "Batch 94 loaded successfully.\n",
      "Batch 95 loaded successfully.\n",
      "Batch 96 loaded successfully.\n",
      "Batch 97 loaded successfully.\n",
      "Batch 98 loaded successfully.\n",
      "Batch 99 loaded successfully.\n",
      "Batch 100 loaded successfully.\n",
      "Batch 101 loaded successfully.\n",
      "Batch 102 loaded successfully.\n",
      "Batch 103 loaded successfully.\n",
      "Batch 104 loaded successfully.\n",
      "Batch 105 loaded successfully.\n",
      "Batch 106 loaded successfully.\n",
      "Batch 107 loaded successfully.\n",
      "Batch 108 loaded successfully.\n",
      "Batch 109 loaded successfully.\n",
      "Batch 110 loaded successfully.\n",
      "Batch 111 loaded successfully.\n",
      "Batch 112 loaded successfully.\n",
      "Batch 113 loaded successfully.\n",
      "Batch 114 loaded successfully.\n",
      "Batch 115 loaded successfully.\n",
      "Batch 116 loaded successfully.\n",
      "Batch 117 loaded successfully.\n",
      "Batch 118 loaded successfully.\n",
      "Batch 119 loaded successfully.\n",
      "Batch 120 loaded successfully.\n",
      "Batch 121 loaded successfully.\n",
      "Batch 122 loaded successfully.\n",
      "Batch 123 loaded successfully.\n",
      "Batch 124 loaded successfully.\n",
      "Batch 125 loaded successfully.\n",
      "Batch 126 loaded successfully.\n",
      "Batch 127 loaded successfully.\n",
      "Batch 128 loaded successfully.\n",
      "Batch 129 loaded successfully.\n",
      "Batch 130 loaded successfully.\n",
      "Batch 131 loaded successfully.\n",
      "Batch 132 loaded successfully.\n",
      "Batch 133 loaded successfully.\n",
      "Batch 134 loaded successfully.\n",
      "Batch 135 loaded successfully.\n",
      "Batch 136 loaded successfully.\n",
      "Batch 137 loaded successfully.\n",
      "Batch 138 loaded successfully.\n",
      "Batch 139 loaded successfully.\n",
      "Batch 140 loaded successfully.\n",
      "Batch 141 loaded successfully.\n",
      "Batch 142 loaded successfully.\n",
      "Batch 143 loaded successfully.\n",
      "Batch 144 loaded successfully.\n",
      "Batch 145 loaded successfully.\n",
      "Batch 146 loaded successfully.\n",
      "Batch 147 loaded successfully.\n",
      "Batch 148 loaded successfully.\n",
      "Batch 149 loaded successfully.\n",
      "Batch 150 loaded successfully.\n",
      "Batch 151 loaded successfully.\n",
      "Batch 152 loaded successfully.\n",
      "Batch 153 loaded successfully.\n",
      "Batch 154 loaded successfully.\n",
      "Batch 155 loaded successfully.\n",
      "Batch 156 loaded successfully.\n",
      "Batch 157 loaded successfully.\n",
      "Batch 158 loaded successfully.\n",
      "Batch 159 loaded successfully.\n",
      "Batch 160 loaded successfully.\n",
      "Batch 161 loaded successfully.\n",
      "Batch 162 loaded successfully.\n",
      "Batch 163 loaded successfully.\n",
      "Batch 164 loaded successfully.\n",
      "Batch 165 loaded successfully.\n",
      "Batch 166 loaded successfully.\n",
      "Batch 167 loaded successfully.\n",
      "Batch 168 loaded successfully.\n",
      "Batch 169 loaded successfully.\n",
      "Batch 170 loaded successfully.\n",
      "Batch 171 loaded successfully.\n",
      "Batch 172 loaded successfully.\n",
      "Batch 173 loaded successfully.\n",
      "Batch 174 loaded successfully.\n",
      "Batch 175 loaded successfully.\n",
      "Batch 176 loaded successfully.\n",
      "Batch 177 loaded successfully.\n",
      "Batch 178 loaded successfully.\n",
      "Batch 179 loaded successfully.\n",
      "Batch 180 loaded successfully.\n",
      "Batch 181 loaded successfully.\n",
      "Batch 182 loaded successfully.\n",
      "Batch 183 loaded successfully.\n",
      "Batch 184 loaded successfully.\n",
      "Batch 185 loaded successfully.\n",
      "Batch 186 loaded successfully.\n",
      "Batch 187 loaded successfully.\n",
      "Batch 188 loaded successfully.\n",
      "Batch 189 loaded successfully.\n",
      "Batch 190 loaded successfully.\n",
      "Batch 191 loaded successfully.\n",
      "Batch 192 loaded successfully.\n",
      "Batch 193 loaded successfully.\n",
      "Batch 194 loaded successfully.\n",
      "Batch 195 loaded successfully.\n",
      "Batch 196 loaded successfully.\n",
      "Batch 197 loaded successfully.\n",
      "Batch 198 loaded successfully.\n",
      "Batch 199 loaded successfully.\n",
      "Batch 200 loaded successfully.\n",
      "Batch 201 loaded successfully.\n",
      "Batch 202 loaded successfully.\n",
      "Batch 203 loaded successfully.\n",
      "Batch 204 loaded successfully.\n",
      "Batch 205 loaded successfully.\n",
      "Batch 206 loaded successfully.\n",
      "Batch 207 loaded successfully.\n",
      "Batch 208 loaded successfully.\n",
      "Batch 209 loaded successfully.\n",
      "Batch 210 loaded successfully.\n",
      "Batch 211 loaded successfully.\n",
      "Batch 212 loaded successfully.\n",
      "Batch 213 loaded successfully.\n",
      "Batch 214 loaded successfully.\n",
      "Batch 215 loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (images, targets) in enumerate(train_loader):\n",
    "    print(f\"Batch {batch_idx} loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "num_classes = len(classes)\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor.cls_score = torch.nn.Linear(in_features, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = optim.SGD(params, lr=0.005, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n",
      "File \u001b[0;32m~/miniconda3/envs/cvpython/lib/python3.9/site-packages/torch/nn/modules/module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cvpython/lib/python3.9/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cvpython/lib/python3.9/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cvpython/lib/python3.9/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cvpython/lib/python3.9/site-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cvpython/lib/python3.9/site-packages/torch/nn/modules/module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1321\u001b[0m             device,\n\u001b[1;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1323\u001b[0m             non_blocking,\n\u001b[1;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1325\u001b[0m         )\n\u001b[0;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for images, targets in train_loader:\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += losses.item()\n",
    "    \n",
    "    print(f\"{epoch+1} loss: {train_loss/len(train_loader):.4f}\")\n",
    "\n",
    "print(\"Finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvpython",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
